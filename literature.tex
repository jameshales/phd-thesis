\chapter{Literature review}\label{literature}

Dynamic epistemic logics are logics of change of knowledge used to reason about how knowledge changes in response to epistemic updates.
Often the effects of epistemic updates on knowledge can be unintuitive or surprising: sometimes announcing a true statement makes it become false, as in Fitch's knowability paradox~\cite{fitch:1963}; sometimes repeating a statement can provide different information each time it is repeated, as in the muddy children puzzle~\cite{barwise:1981, vanditmarsch:2007}. 
Being able to reason about changes in knowledge has applications in a range of areas:
in artificial intelligence and information science we want to represent and reason about updates in knowledge bases and ontologies;
in the study of network protocols and computer security we want to ensure that information communicated through a network results in the desired knowledge-based goals and doesn't result in the leaking of sensitive information; and
in economics and game theory we want to reason about processes or games with imperfect knowledge, where actions may provide players with additional information that's required to inform their decisions.
For some applications it's useful to know the effects of specific epistemic updates~\cite{plaza:1989,baltag:1998}, such as when a robot updates its internal knowledge base with with new sensor information, when a participant in a network protocol sends or receives a message containing new information, or a player in a game performs an action that reveals additional information about the game state.
At other times it's useful to reason about arbitrary epistemic updates, quantifying over epistemic updates in a goal-directed fashion~\cite{balbiani:2007,agotnes:2010,vanditmarsch:2009}, such as when a robot must sense enough of its environment to navigate an area, when a protocol designer must design a protocol that achieves desired knowledge-based goals without leaking sensitive information, or when a player in a game must choose a strategy that increases the information available in order to better inform their decisions.
Formal logics of knowledge have existed for many decades~\cite{vonwright:1951,hintikka:1957,hintikka:1961,hintikka:1962}, whilst logics for reasoning about the effects of specific epistemic updates have only arisen relatively recently~\cite{plaza:1989,gerbrandy:1997,baltag:1998}. 
Much more recently logics for reasoning about arbitrary epistemic updates have been considered~\cite{balbiani:2007,vanditmarsch:2009,agotnes:2010}, and logics of this variety are the focus of our research.
This review summarises the development of logics of knowledge, logics of specific epistemic updates and finally logics of arbitrary epistemic updates.  

\section{Logics of knowledge}

Epistemic logic is the modal logic of knowledge.
Modal logics extend propositional logic with modal operators that qualify the truth of statements in the logic.
In epistemic logic, the modal operators allow us to qualify the truth of a statement by saying that an agent knows that the statement is true.
For example, we can qualify the proposition ``The coin has landed heads up'' by saying ``Alice knows that the coin has landed heads up''.
Modal operators may also be nested, allowing us to make statements about an agent's knowledge about its own or another agent's knowledge.
For example, we could say ``Alice knows that Alice knows that the coin has landed heads up'', or ``Bob doesn't know that Alice knows that the coin has landed heads up''.

The semantics for many modal logics, including epistemic logic, are based in relational structures known as Kripke models~\cite{kripke:1963,blackburn:2001}.
A Kripke model is a relational structure over a set of ``worlds'', where each world has a set of propositional atoms that are true at that world, and each agent has an accessibility relation defined over the worlds.
The worlds of a Kripke model can be seen as representing the possible ways that the ``real'' world could be.
An agent considers another world to be ``possible'' from a given world if that world is accessible from the given world through the agent's accessibility relation in the Kripke model.
An agent may consider multiple worlds to be possible, representing the agent's uncertainty as to which world is the real world.
An agent is said to ``know'' that a statement is true in a given world if that statement is true on each of the worlds that the agent considers possible from the given world.
Generally speaking, the more worlds that an agent considers possible, the less the agent knows.

Variants of modal logic may attribute different intuitive meanings to its modal operators, often depending on properties required of the Kripke models that are under consideration.
For example epistemic logics usually require that agents always consider the real world to be possible, as otherwise the agent might ``know'' a statement that is actually false in the real world.
By contrast, doxastic logics, which are logics of belief, often relax this constraint as it's reasonable for an agent to ``believe'' a statement that is actually false in the real world.

\subsection{Modal and epistemic logics}

Lewis and Langford are widely acknowledged as the progenitors of early modal logic, with the earliest symbolic treatment of modal logic dating back to work by Lewis in 1912, and leading to a book with Langford~\cite{langford:1959} in 1959.
Early work in modal logic was mostly syntactic, lacking any formal semantics.
Carnap~\cite{carnap:1946, carnap:1947} first considered the notion of possible worlds to represent the semantics of modal logics, and other authors, amongst them Hintikka~\cite{hintikka:1957, hintikka:1961} and Kripke~\cite{kripke:1959} further developed these semantics, resulting in the final form by Kripke~\cite{kripke:1963}, the namesake of Kripke models and Kripke semantics for modal logics.
von Wright~\cite{vonwright:1951} was responsible for the first logical analysis of knowledge in terms of modal logic in 1951, and this was further developed by Hintikka~\cite{hintikka:1957,hintikka:1961} culminating in the first book-length treatment of the subject by Hintikka~\cite{hintikka:1962} in 1962.

\subsection{Common knowledge}

The first work on the topic of common knowledge was by Lewis~\cite{lewis:1969} and later work was by McCarthy, Sato, Hayashi and Igarishi~\cite{mccarthy:1979}.
Common knowledge is described by McCarthy as what ``any fool knows''; for a statement to be common knowledge, it is required that everyone knows that the statement is true, that every agent knows that every agent knows that the statement is true, and so on.
Whereas the definition of common knowledge of Lewis and McCarthy was in terms of modal logics, Aumann~\cite{aumann:1976} gave an alternative definition for common knowledge using Aumann structures and the meet of structures rather than Kripke models and modal formulas.
Common knowledge is of interest in economics and game theory, where common knowledge of rationality, rules and outcomes is assumed in order to permit backwards-induction reasoning about games~\cite{aumann:1995}.
Aumann~\cite{aumann:1976} discusses common knowledge with a focus towards discussing economics and game theory. 
Lehmann~\cite{lehmann:1984} and Halpern and Moses~\cite{halpern:1985} considered common knowledge in depth, and the book by Fagin, Halpern, Moses and Vardi~\cite{fagin:1995} gives a survey of much of their work in this area.

\subsection{Alternative logics of knowledge}

Non-modal logics of knowledge have been considered. 
Aumann~\cite{aumann:1976} proposed an event-based approach using Aumann structures, which represents knowledge as an operator on events rather than reasoning about knowledge using logical formulas.
There is in fact a one-to-one correspondence between epistemic Kripke models and Aumann structures~\cite{fagin:1995}.
A number of authors, among them van Emde Boas, Groenendijk, and Stokhof~\cite{vanemdeboas:1980}, Fagin and Vardi~\cite{fagin:1985}, Mertens and Zamir~\cite{mertens:1985} and Fagin, Halpern and Vardi~\cite{fagin:1991} have considered modeling knowledge and belief using an infinite hierarchy of sets representing the relative strength or plausibility of each piece of knowledge.
This representation lends itself easily to the concept of belief revision, discussed in the next section.
Fagin, Halpern and Vardi~\cite{fagin:1991} discussed the relationship between this representation of knowledge and belief with modal logic.  

%\subsection{Applications of logics of knowledge}

%\begin{enumerate}
    %\item McCarthy 1979 - Knowledge and belief for machines~\cite{mccarthy:1979b}
    %\item Aumann [5~\cite{aumann:1976},6~\cite{aumann:1999},7~\cite{aumann:1995}] -
        %Economics and Game theory

    %\item Orlowska 1989 - Knowledge as operator on events~\cite{orlowska:1989}
    %\item Brandenburger, et al. 1993, etc. - "Direct" representation of
        %knowledge~\cite{brandenburger:1993}
    %\item Fagin, Halpern, Vardi 1991 - Relationship of Brandenburger knowledge
        %to ML~\cite{fagin:1991}
    %\item Levesque 1984a - KD45 as knowledge~\cite{levesque:1984a}
    %\item Fagin and Halpern 1988a, Levesque 1984b - KD45 as
        %belief~\cite{fagin:1987, levesque:1984b}
    %\item Friedman and Halpern 1977, Kraus and Lehmann 1988, Moses and Shoham
        %1933, Voorbraak 1992 - System with knowledge and belief, interaction
    %between knowledge and belief~\cite{friedman:1997, kraus:1988, moses:1993,
    %voorbraak:1992}
    %% TODO AI, economics, game theory
%\end{enumerate}

\section{Logics of specific epistemic updates}

Dynamic epistemic logics consider how knowledge changes as a result of epistemic updates that provide agents with additional information.
For our purposes we generally assume that epistemic updates are purely informative, so they may cause knowledge to change, but not the truth of the propositional atoms that the knowledge is about.
For example, after flipping a coin, if Alice were to tell Bob ``The coin has landed heads up'', this would be a purely informative epistemic update, as the effect is only on Alice and Bob's knowledge.
However the act of Alice flipping the coin would not be purely informative, as it has an effect outside of Alice and Bob's knowledge, specifically on the truth of the statement that ``The coin has landed heads up''.
We also assume that epistemic updates provide additional information monotonically, so they may not cause agents to forget or revise information.
For example, if Alice wasn't wearing her glasses when she looked at the coin she might look again and tell Bob that actually the coin landed tails up, causing Bob to revise the information he was previously offered.
If Alice looks yet again she might tell Bob that she's now unsure about whether the coin has landed heads up, causing Bob to forget the information he was previously offered, as it was possibly unreliable.
There are models for epistemic updates that permit propositional change~\cite{vanbenthem:2006} or that that permit revision of information~\cite{alchourron:1985}, however they are not the focus of the present work.

Previous work in dynamic epistemic logic has considered how knowledge changes in response to specific epistemic updates.
These logics typically extend epistemic logic with operators that denote that a specific epistemic update results in a statement becoming true.
For example, we can say that ``After Alice tells Bob that the coin has landed heads up, Bob knows that the coin has landed heads up.''
Logics of this form have been considered for a number of different models for epistemic updates.
Often epistemic updates are modelled as operations on Kripke models, but there are examples of logics where this is not the case.

Notable logics for reasoning about specific epistemic updates include the logic of belief revision of Alchourr{\'o}n, G{\"a}rdenfors and Makinson~\cite{alchourron:1985}, the logic of public announcements of Plaza~\cite{plaza:1989} and Gerbrandy and Groenvald~\cite{gerbrandy:1997}, the arrow update logic of Kooi and Renne~\cite{kooi:2011a}, the logic of epistemic actions of van Ditmarsch~\cite{vanditmarsch:1999, vanditmarsch:2000, vanditmarsch:2002} and the logic of action models of Baltag, Moss and Solecki~\cite{baltag:1999, baltag:2004}.
A survey of some of these logics and related areas is given in the book by van Ditmarsch, van der Hoek and Kooi~\cite{vanditmarsch:2007}.

\subsection{Public announcement logic}

Public announcements are simple epistemic updates that consist of a true statement being publicly announced to all agents at once.
The public nature of the announcement means that every agent receives the announcement, every agent knows that every agent receives the announcement, every agents knows that every agents knows that every agent receives the announcement, and so on. 
The effect of publicly announcing a true statement is often that the statement becomes common knowledge amongst agents. 
For example, if Alice, Bob and Carol are in a room and Alice publicly announces that ``The coin has landed heads up'', then this statement becomes common knowledge amongst Alice, Bob and Carol.
Not only does Bob now know that the coin has landed heads up, Carol knows, Bob knows that Carol knows, Carol knows that Bob knows, and so on.
However there are examples where public announcements of true statements do not result in common knowledge, such as the Moore sentence ``The coin has landed heads up but Bob doesn't know that the coin has landed heads up''.
If Bob knew that this statement was true, then Bob would know that the coin has landed heads up, but this would contradict the second part of the statement, that says that Bob doesn't know that the coin has landed heads up.

The public announcement logic was introduced by Plaza~\cite{plaza:1989}, and Gerbrandy and Groenvald~\cite{gerbrandy:1997}.
Public announcement logic extends epistemic logic with an operator that denotes that publicly announcing a true statement results in another statement becoming true.
Public announcements may be modelled as operations on Kripke models by restricting the worlds of the Kripke models to those worlds where the publicly announced statement is true, removing those worlds where the statement is false, as in the treatment by Plaza~\cite{plaza:1989}.
Alternatively public announcements may be modelled as operations on Kripke models by restricting the accessibility relations of the Kripke models so that agents only consider worlds possible if those worlds satisfy the publicly announced statement, as in the treatment by Gerbrandy and Groenvald~\cite{gerbrandy:1997}.
Plaza~\cite{plaza:1989} formulated and axiomatised a multi-agent public announcement logic with common knowledge operators, but without introspection of knowledge, i.e.  agents cannot reason about their own knowledge. 
Gerbrandy and Groenvald~\cite{gerbrandy:1997} formulated and axiomatised a multi-agent public announcement logic without common knowledge operators, but with introspection of knowledge.
Baltag, Moss and Solecki~\cite{baltag:1998,baltag:2004} provided a sound and complete axiomatisation of the public announcement logic with common knowledge operators and introspection of knowledge as a special case of their action model logic with common knowledge.

Public announcements are a very simple form of epistemic update, as the information communicated by a public announcement must be communicated publicly to all agents.
Public announcements cannot model epistemic updates that provide information to only some of the agents in the system, or that provides different information to each agent.
However public announcements are suited to some interesting problems; for example, Fitch's knowability paradox~\cite{fitch:1963} can be adequately modelled and reasoned about with the public announcement logic, as can the muddy children puzzle~\cite{barwise:1981, vanditmarsch:2007}.

\subsection{Action model logic}

Action models are a very general notion of epistemic updates that generalise public announcements.
Unlike public announcements, action models are able to represent epistemic updates that provide information privately to some of the agents in the system and provide different information to each agent in the system.
When considering epistemic updates that communicate information privately to some agents, there are a number of ways in which the other agents in the system can interpret that epistemic update. 
For example, suppose that after flipping a coin, Alice looks at the coin so that Bob sees Alice looking at the coin, but Bob can't see the coin himself. Then Bob would know that either Alice knows that the coin has landed heads up or Alice knows that the coin has landed tails up, but Bob himself doesn't know which is actually the case.
If instead Alice were to sneakily look at the coin so that Bob doesn't see her looking, then Alice would know that the coin has landed heads up, but Bob wouldn't know that Alice knows.

Action models are relational structures similar to Kripke models.
An action model is a relational structure over a set of ``actions'', where each action has a precondition determining when the action can take place, and each agent has an accessibility relation defined over the actions.
The actions of an action model can be seen as representing the possible epistemic updates that may have occurred.
As in a Kripke model, agents may consider actions to be ``possible'', and an agent considering multiple actions possible represents the agent's uncertainty as to which epistemic update has actually occurred.
For example, when Alice looks at the coin after flipping it, she only considers one epistemic update to have been possible: where she learns that the coin has landed heads up; Bob however considers two epistemic updates to have been possible: one where Alice learns that the coin has landed heads up, and one where Alice learns that the coin has landed tails up.
This uncertainty is represented in an action model by having separate actions in the action model, one representing Alice learning that the coin has landed heads up and one representing Alice learning that the coin has landed tails up, and giving Alice and Bob different accessibility relations over the actions, so that Alice only considers one action possible, but Bob considers both actions possible.

The action model logic was introduced by Baltag, Solecki and Moss~\cite{baltag:1998, baltag:1999}.
Action model logic extends epistemic logic with an operator that denotes that executing a specific action model results in a statement becoming true.
The execution of an action model may be modelled as an operations on Kripke models, by taking a sort of ``product'' with the action model, followed by a restriction of the resulting Kripke model according to the satisfaction of the preconditions in the action model.
This can be seen as a generalisation of the world-restricting model of public announcements used by Plaza~\cite{plaza:1989}.
Baltag, Solecki and Moss~\cite{baltag:1998} provided a sound and complete axiomatisation for the logic with and without common knowledge operators.
Later work by Baltag and Moss~\cite{baltag:2004} emphasised the generality of the action model approach, providing many examples of action models representing various kinds of epistemic updates, including public announcements.
Baltag and Moss~\cite{baltag:2004} introduced the notion of an action signature, representing a class of action models that have the same relational structure but which have different formulas as preconditions.
They show that sublanguages of the action model logic can be defined by restricting the possible action models to those corresponding to sets of action signatures, and that the resulting sublanguages have a sound and complete axiomatisation.
This gives for example a sound and complete axiomatisation for the public announcement logic, the logic of completely private announcements to groups and the logic of common knowledge of alternatives.

Although the notion of information change that the action model logic captures is intuitively explained in a setting of knowledge, the formulation that Baltag, Moss and Solecki~\cite{baltag:1998} provide is in a more general modal setting that can be applied not only to epistemic logic, but to other modal logics, such as doxastic logics.
Whereas public announcements can only represent true epistemic updates, where the information that is communicated must actually be true in the real world, there is no such restriction for action models.
It is possible in a setting of doxastic logic for an action model to represent epistemic updates containing false information, leading agents to believe that false statements are true.
Baltag and Moss~\cite{baltag:2004} refer to the epistemic updates that action models represent as {\em justifiable changes in belief}, meaning that it is not assumed that action models communicate true information, only that they communicate information that is assumed to be trustworthy.
It is possible for action models to represent intentionally deceptive epistemic updates, such as if Alice knows that the coin has landed heads up, but tells Bob that the coin has landed tails up.
It is also possible for action models to represent unintentionally false epistemic updates, such as if Bob believes that the coin landed tails up, when it in fact did not, but then tells Carol that the coin landed tails up. 
However action models are not capable of {\em revising} beliefs.
That is, after Bob has been lead to believe that the coin has landed tails up, it is not possible to convince him otherwise using an action model.
Action models represent in some sense a monotonic change of knowledge or belief.

\subsection{Arrow update logic}

Arrow updates are another generalisation of public announcements.
Unlike public announcements, arrow updates are able to represent epistemic updates that provide different information to each agent in the system.
The base system of arrow updates assumes that the effects of an arrow update are common knowledge to the agents in a system, and so arrow updates cannot represent epistemic updates that provide information privately to agents~\cite{kooi:2011a}.
However generalised arrow updates are able to represent such epistemic updates, and in fact every action model is update-equivalent to a generalised arrow update, and vice versa~\cite{kooi:2011b}.

The arrow update logic was introduced by Kooi and Renne~\cite{kooi:2011a}.
Arrow update logic extends epistemic logic with an operator that denotes that executing a finite set of arrow updates results in a statement becoming true.
An arrow update consists of a statement, called the source condition, an agent, and another statement, called the target condition.
The execution of an individual arrow update may be modelled as an operation on Kripke models by restricting the edges in the given agent's accessibility relation so that worlds that satisfy the given source condition only have edges to worlds that satisfy the given target condition.
The execution of a finite set of arrow updates may be modelled by restricting the edges in the Kripke model's accessibility relations to those edges that are preserved as a result of executing any of the arrow updates in the set individually.
Whereas action models may be seen as a generalisation of the world-restricting model of public announcements used by Plaza~\cite{plaza:1989}, arrow updates may be seen as a generalisation of the edge-restricting model of public announcements used by Gerbrandy and Groenvald~\cite{gerbrandy:1997}.
Kooi and Renne~\cite{kooi:2011a} provide a sound and complete axiomatisation for the logic, and compare arrow updates to action models, showing that arrow updates may be represented as action models, but are sometimes exponentially more succinct than action models.
Arrow updates are less general than action models, however Kooi and Renne~\cite{kooi:2011b} also consider a generalised arrow update that can represent any action model up to update-equivalence.

\subsection{Belief revision}

In contrast to the true epistemic updates of public announcements, and the justifiable, monotonic epistemic updates of action models, methods for belief revision consider ways in which agents can revise their beliefs in the light of new information.
The system of truth maintenance of Doyle~\cite{doyle:1979} is an early approach to belief revision in the setting of artificial intelligence, which models a ``knowledge base'' of beliefs along with the reasons for those beliefs, which are used to revise those beliefs when contradicting information is discovered. 
Levi~\cite{levi:1983} and Harper~\cite{harper:1976} provided a model of rational belief change which models beliefs and belief revision using Bayesian probability.

More recent developments in belief revision are heavily influenced by the AGM approach to belief revision, named for Alchourr{\'o}n, G{\"a}rdenfors and Makinson~\cite{alchourron:1985}.
The AGM approach models a single agent's beliefs with a belief set, consisting of a set of propositional formulas.
An epistemic update is represented by an operation on the belief set called a revision, which consists of adding a new formula to the belief set, and then removing contradicting formulas from the belief set until the resulting belief set is consistent.
Often there are multiple ways to remove formulas from the belief set that will result in a consistent belief set, and so the AGM approach uses a model of entrenchment, representing how strongly certain beliefs are held, in order to determine which formulas should be removed in favour of others.
Alchourr{\'o}n, G{\"a}rdenfors and Makinson do not provide a logical framework for reasoning about their method of belief revision, and their approach is limited in the sense that it only deals with propositional beliefs, and therefore cannot represent introspective beliefs (beliefs about the agent's own beliefs) or beliefs about other agents' beliefs. 

van Benthem~\cite{vanbenthem:1989, vanbenthem:1994, vanbenthem:1996}, Jaspars~\cite{jaspars:1994} and de Rijke~\cite{derijke:1994} applied dynamic modal logic to doxastic logic to model information change, taking influences from the AGM approach to belief revision.
This provided a logical framework for reasoning about belief revision, however the results still did not allow introspection of beliefs. 
Subsequent work by Lindstr{\"o}m and Rabinowicz~\cite{lindstrom:1999a, lindstrom:1999b} and Segerberg~\cite{segerberg:1999a, segerberg:1999b} developed a full dynamic doxastic logic, allowing reasoning about belief revision with introspective beliefs.
These logics introduce operators that denote that revising an agent's beliefs with a new statement results in another statement becoming true.

%\subsection{Other logics} %\begin{enumerate} %\item Groenendijk and Stokhot [81]~\cite{groenendijk:1991} - Philosophy of information change and
        %linguistics
    %\item Harel and Kozen and Tiuryu [93]~\cite{harel:1983},
        %Pratt~\cite{pratt:1980}, Halpern [17~\cite{benari:1982}, 90~\cite{halpern:1983},
        %28~\cite{berman:1982}], Parikh [161~\cite{parikh:1978}, Goldblatt
            %[79~\cite{goldblatt:1992}] - Dynamic modal
        %logic
    %\item Halpern and Moses [88~\cite{halpern:1985}] - Common knowledge is hard to achieve
    %\item Parikh and Ramanujan [164~\cite{parikh:1985}] - History-based semantics for change of
        %knowledge
    %\item Chandy and Misra [35~\cite{chandy:1986}] - Minimum information flow
    %\item Veltman~\cite{veltman:1996} - Update semantics
%\end{enumerate}
%\begin{enumerate}
    %\item van Ditmarsch [42~\cite{vanditmarsch:1999}, 43~\cite{vanditmarsch:2000},
            %44~\cite{vanditmarsch:2002}] - epistemic actions
    %\item van Benthem and van Eijck and Kooi [26~\cite{vanbenthem:2006}] - Factual change
    %\item Aucher [4~\cite{aucher:2005}], van Ditmarsch
        %[48~\cite{vanditmarsch:2005}], van Benthem and Liu
        %[27~\cite{vanbenthem:2007}]  -
        %Preference-based belief revision
    %\item Leveaque, Lakemeyer, Demolombe [125~\cite{lakemeyer:2000}, 41~\cite{demolombe:2003}] - AI-flavoured semantics
%\end{enumerate}

\section{Logics of arbitrary epistemic updates}

A more recent development in the field of dynamic epistemic logic concerns logics for reasoning about arbitrary epistemic updates.
These logics extend epistemic logic or dynamic epistemic logics for specific epistemic updates with quantifiers that denote either that every epistemic update or some epistemic update results in a statement becoming true.
These quantifiers could be applied to the development of network protocols, where we want to reason about the existence of epistemic protocols that achieve desired knowledge-based goals, or in the verification of secure computer systems, where we want to guarantee that no sequence of operations in the system will lead to sensitive information being leaked to unauthorised agents.

A closely related problem is that of synthesising epistemic updates that achieve desired knowledge-based goals.
For example, in the development of network protocols, if a protocol exists that would achieve a desired knowledge-based goal, then in principle a synthesis procedure could be applied to construct a specific protocol that can be used in practice, or in the verification of secure computer systems, if there is a sequence of operations that results in the system leaking sensitive information, then a synthesis procedure could be applied to construct an example of such a sequence of operations, assisting in debugging and securing the system.

\subsection{Arbitrary public announcement logic}

Early considerations of arbitrary epistemic updates were in relation to the concept of knowability.
A true statement is knowable by an agent if it is possible for the agent to know that it is true as a result of an epistemic update.
An example of an unknowable statement was given by Moore (see Hintikka~\cite{hintikka:1962}) which takes the form of ``The coin has landed heads up but Bob doesn't know that the coin has landed heads up''.
If Bob knew that this statement was true, then Bob would know that the coin has landed heads up, but this would contradict the second part of the statement, that says that Bob doesn't know that the coin has landed heads up.
Knowability was considered by Fitch~\cite{fitch:1963} in relation to the verification principle, which says that ``every true statement is knowable''.
Fitch shows that if every true statement is knowable then every true statement must be known; this is known as Fitch's knowability paradox.
It shows that if we accept the verification principle then the notions of truth and knowledge become equivalent, and therefore that the notion of knowledge is redundant in such a setting.
van Benthem~\cite{vanbenthem:2004} considers knowability in the setting of dynamic epistemic logic and dismisses a number of logical treatments of knowledge that attempt to accept the verification principle by weakening the rules for knowledge.
van Benthem~\cite{vanbenthem:2004} also considers the notion of a successful statement, which is a true statement that is known by an agent after it is announced to that agent.
For example, if Bob were to be told that the coin has landed heads up then he would know that the coin has landed heads up, and so ``the coin has landed heads up'' is a successful statement.
All successful statements are knowable, and so the previous example of an unknowable statement is also an example of an unsuccessful statement; after telling Bob that ``the coin has landed heads up and Bob doesn't know that the coin has landed heads up'', Bob does not know that this statement is true because its truth has been invalidated by telling it to Bob.
These treatments of knowable and successful statements introduce an informal syntactic notion of ``what can be known'' that bears some similarity to quantifiers over epistemic updates.


The arbitrary public announcement logic (\logicApal{}) was introduced by Balbiani et al.~\cite{balbiani:2007}.
\logicApal{} extends public announcement logic with quantifiers that denote either that every public announcement or some public announcement results in a statement becoming true.
This work was partially motivated by Fitch's knowability paradox, and the concept of knowability may be encoded using the quantifiers introduced by the logic.
Balbiani et al.~\cite{balbiani:2007} provided a number of semantic results for the \logicApal{}, along with a sound and complete axiomatisation, however the logic was shown to be undecidable in the setting of multiple agents by French and van Ditmarsch~\cite{french:2008}.
Balbiani et al.~\cite{balbiani:2007} also suggested a generalisation of the \logicApal{} to quantify over more general classes of epistemic updates, such as action models.

%\begin{enumerate}
    %\item Moore (see Hintikka 1962) - $K(\phi \land \neg K \phi)$~\cite{hintikka:1962}
    %\item Fine~\cite{fine:1970} - Propositional quantifiers
    %\item van Benthem~\cite{vanbenthem:2004} - knowable/successful formulas
    %\item Balbiani et al.~\cite{balbiani:2007} - arbitrary public announcement logic
    %\item van Ditmarsch and French~\cite{vanditmarsch:2008} - undecidability
    %\item Balbiani et al.~\cite{balbiani:2008} - ???
    %\item van Ditmarsch, van der Hoek and Iliev~\cite{vanditmarsch:2011} - ???
%\end{enumerate}

\subsection{Group announcement and coalition announcement logic}

Two logics related to \logicApal{} are the group announcement logic (\logicGal{}) and the coalition announcement logic (\logicCal{}) of {\AA}gotnes and van Ditmarsch~\cite{agotnes:2008,agotnes:2010}. 
Compared to \logicApal{} the quantifiers of \logicGal{} restrict the public announcements that are quantified over to group announcements.
A group announcement consists of a public announcement that each agent in a group knows a particular statement is true.
Each agent may only announce statements that they know to be true.
\logicGal{} extends public announcement logic with quantifiers that denote, for a given group of agents, either that every group announcement or some group announcement that can be made by the group results in a statement becoming true.
Coalition announcements are similar, but differ from group announcements in that agents outside of the coalition are also able to make public announcements that may sabotage whatever the coalition of agents is attempting to achieve through its announcements.
{\AA}gotnes et al.~\cite{agotnes:2010} provide a sound and complete axiomatisation of \logicGal{}, along with expressivity results and a complexity result for model checking, and {\AA}gotnes, van Ditmarsch and French~\cite{agotnes:2014} showed that \logicGal{} is undecidable.
It is yet unknown whether \logicGal{} and \logicCal{} are expressively equivalent.

%\begin{enumerate}
    %\item {\AA}gotnes et al.~\cite{agotnes:2010} - group announcement logic
    %\item Pauly~\cite{pauly:2001} - GAL embeds coalition logic
    %\item de Lima~\cite{delima:2011} - Alternating time temporal announcement logic
    %\item {\AA}gotnes and van Ditmarsch~\cite{aagotnes:2008b} - Coalitions and announcements ???
%\end{enumerate}

\subsection{DEL-sequents}

% TODO

\subsection{Other related logics}

The subset space logic of Dabrowski, Moss and Parikh~\cite{dabrowski:1996} associates with each Kripke model a topology of non-empty subsets of the worlds in the Kripke model, and introduces quantifiers that quantify over these subsets of worlds.
Whereas \logicApal{} quantifiers over public announcements, essentially the modally definable subsets of the worlds in a Kripke model, the subset space logic may quantify over subsets that are not modally definable.
Recent work by W{\'a}ng and {\AA}gotnes~\cite{wang:2013a,wang:2013b} has extended the subset space logic to multiple agents, and shown that the subset space logic may be used as the basis of an alternative semantics for the public announcement logic, and recent work by Balbiani, van Ditmarsch and Kudinov~\cite{balbiani:2013} has demonstrated that the subset space logic may be used as the basis of an alternative semantics for reasoning about arbitrary public announcements.

The arbitrary arrow update logic (\logicAaul{}) was recently proposed by van Ditmarsch, van der Hoek and Kooi~\cite{vanditmarsch:2014}.
\logicAaul{} extends arrow update logic with quantifiers that denote either that every arrow update or some arrow update results in a statement becoming true. 
van Ditmarsch, van der Hoek and Kooi~\cite{vanditmarsch:2014} have presented preliminary results focussing on the relative expressivity of \logicAaul{} with epistemic logic, epistemic logic with common knowledge operators, and \logicApal{}.

The alternative logic for knowability of Wen, Liu and Huang~\cite{wen:2011} introduces quantifiers that quantify over subrelations of the accessibility relations of Kripke models.
Whereas \logicAaul{} quantifies over arrow updates, essentially a form of modally definable subrelations of a Kripke model, the alternative logic for knowability may quantify over subrelations that are not modally definable.
Subrelations are less general than refinements, which may duplicate states as well as remove edges from accessibility relations.
Wen, Liu and Huang~\cite{wen:2011} discuss this logic in the context of knowability, with comparisons to \logicApal{}, and demonstrate that in the single-agent case the logic is equivalent to \logicApal{}, and in the multi-agent case the logic is equivalent to the subset space logic on the class of downward closed multi-agent subset frames.

\subsection{Refinement modal logic}

The refinement modal logic (\logicRml{}) of van Ditmarsch and French~\cite{vanditmarsch:2009} introduces quantifiers over a much more general class of epistemic updates than the logics considered previously.
\logicRml{} is related to the bisimulation quantified modal logic of French~\cite{french:2006}, which introduces an operator for quantifying over the pointed Kripke models that are bisimilar to the pointed Kripke model currently being considered, except for the value of a propositional atom that is allowed to vary.
Bisimulations are an important concept in the semantics of modal logics, that correspond to a notion of equivalence of Kripke models: if two pointed Kripke models are bisimilar then they are indistinguishable to any modal formula.
For two Kripke models to be considered bisimilar there must exist a bisimulation relation that satisfies the three conditions known as {\bf atoms}, {\bf forth} and {\bf back}.
Refinements are related to bisimulations: for a Kripke model to be a refinement of another Kripke model, there must exist a relation from one Kripke model to the other that satisfies {\bf atoms} and {\bf forth}.
Refinements can be seen as one direction of a bisimulation; whereas bisimulation corresponds is an equivalence relation, refinement are a partial ordering.
The refinement modal logic of van Ditmarsch and French~\cite{vanditmarsch:2009} quantifies over the pointed Kripke models that are refinements of the pointed Kripke model currently being considered.
Whereas the quantifier in the bisimulation quantified modal logic of French~\cite{french:2006} binds a propositional atom as a variable, the quantifier in \logicRml{} binds no variables.
van Ditmarsch and French~\cite{vanditmarsch:2009} provide semantic results to justify the view that refinements correspond to a very general notion of epistemic updates, in particular that the result of executing an action model on a Kripke model is a refinement of the original Kripke model, and any refinement of a finite Kripke model corresponds to the result of executing an action model.
van Ditmarsch and French~\cite{vanditmarsch:2009} also compare \logicRml{} to the arbitrary action model logic suggested by Balbiani et al.~\cite{balbiani:2007}, conjecturing that adding the operator from the action model logic to the \logicRml{} yields a logic equivalent to the arbitrary action model logic.
In subsequent work van Ditmarsch, French and Pinchinat~\cite{vanditmarsch:2010} provide a sound and complete axiomatisation for the single agent variant of \logicRml{} over the class of all Kripke models.
The axiomatisation takes the form of reduction axioms, admitting a provably correct translation from \logicRml{} to the underlying modal logic, and as a corollory means that the logic is decidable.
van Ditmarsch, French and Pinchinat~\cite{vanditmarsch:2010} also considered a variant of \logicRml{} that extends the modal $\mu$-calculus.
Later work by Bozzelli, van Ditmarsch and Pinchinat~\cite{bozzelli:2014a} gave succinctness results and complexity bounds for the decision problem for the single-agent \logicRml{} over the class of all Kripke models, and Achilleos and Lampis~\cite{achilleos:2013} provided complexity results for the model-checking problem in addition to tighter complexity bounds for the decision problem.
