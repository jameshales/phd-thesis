\chapter{Literature review}\label{literature}

Dynamic epistemic logics are logics of change of knowledge used to reason about how knowledge changes in response to epistemic updates.
Often the effects of epistemic updates on knowledge can be unintuitive or surprising: sometimes announcing a true statement makes it become false, as in Fitch's knowability paradox~\cite{fitch:1963}; sometimes repeating a statement can provide different information each time it is repeated, as in the muddy children puzzle~\cite{barwise:1981, vanditmarsch:2007}. 
Being able to reason about changes of knowledge has applications in a range of areas:
in artificial intelligence and information science we want to represent and reason about updates in knowledge bases and ontologies;
in the study of network protocols and computer security we want to ensure that information communicated through a network results in the desired knowledge-based goals
 and that information that is communicated doesn't result in the leaking of sensitive information; and
in economics and game theory we want to reason about processes or games with imperfect knowledge, where actions may provide players with additional information that's required to inform their decisions.
For some applications it's useful to know the effects of specific epistemic updates~\cite{plaza:1989,baltag:1998}, such as when a robot updates its internal knowledge base with with new sensor information, when a participant in a network protocol sends or receives a message containing new information, or a player in a game performs an action that reveals additional information about the game state.
At other times it's useful to reason about arbitrary epistemic updates in a goal-directed fashion~\cite{balbiani:2007,agotnes:2010,vanditmarsch:2009}, such as when a robot must sense enough of its environment to navigate an area, when a protocol designer must design a protocol that achieves desired knowledge-based goals whilst remaining secure, or when a player in a game must choose a strategy that maximises the information available in order to better inform their decisions.
Formal logics of knowledge have existed for many decades~\cite{vonwright:1951,hintikka:1957,hintikka:1961,hintikka:1962}, whilst logics for reasoning about the effects of specific epistemic updates have only arisen relatively recently~\cite{plaza:1989,gerbrandy:1997,baltag:1998}. 
Much more recently logics for reasoning about arbitrary epistemic updates have been considered~\cite{balbiani:2007,vanditmarsch:2009,agotnes:2010}, and logics of this variety are the focus of our research.
This review summarises the development of logics of knowledge, logics of specific epistemic updates and finally logics of arbitrary epistemic updates.  

\section{Logics of knowledge}

Epistemic logic is the modal logic of knowledge.
Modal logics extend propositional logic with modal operators that qualify the truth of statements in the logic.
In epistemic logic, the modal operators allow us to qualify the truth of a statement by saying that an agent knows that the statement is true.
For example, we can qualify the proposition ``The coin has landed heads up'' by saying ``Alice knows that the coin has landed heads up''.
Modal operators may also be nested, allowing us to make statements about an agent's knowledge about its own or another agent's knowledge.
For example, we could say ``Alice knows that Alice knows that the coin has landed heads up'', or ``Bob doesn't know that Alice knows that the coin has landed heads up''.

The semantics for many modal logics, including epistemic logic, are based in relational structures known as Kripke models~\cite{kripke:1963,blackburn:2001}.
A Kripke model is a labelled graph over a set of worlds, where each world has a set of propositional atoms that are true at that world, and each agent has an accessibility relation defined over the worlds.
At a particular world, an agent considers another world to be ``possible'' if that world is accessible from the given world through the agent's accessibility relation in the Kripke model.
An agent is said to ``know'' that a statement is true in a given world if that statement is true on each of the worlds that the agent considers possible.

Variants of modal logic may attribute different intuitive meanings to its modal operators, often depending on properties required of the Kripke models that are under consideration.
For example epistemic logics usually require that agents always consider the current, real, world to be possible, as otherwise the agent might ``know'' a statement that is actually false in the real world.
By contrast, doxastic logics, which are logics of belief, often relax this constraint as it's reasonable for an agent to ``believe'' a statement that is actually false in the real world.

\subsection{Modal and epistemic logics}

Lewis and Langford are widely acknowledged as the progenitors of early modal logic, with the earliest symbolic treatment of modal logic dating back to work by Lewis in 1912, and leading to a book with Langford~\cite{langford:1959} in 1959.
Early work in modal logic was mostly syntactic, lacking any formal semantics.
Carnap~\cite{carnap:1946, carnap:1947} first considered the notion of possible worlds to represent the semantics of modal logics, and other authors, amongst them Hintikka~\cite{hintikka:1957, hintikka:1961} and Kripke~\cite{kripke:1959} further developed these semantics, resulting in the final form by Kripke~\cite{kripke:1963}, the namesake of Kripke models and Kripke semantics for modal logics.
von Wright~\cite{vonwright:1951} was responsible for the first logical analysis of knowledge in terms of modal logic in 1951, and this was further developed by Hintikka~\cite{hintikka:1957,hintikka:1961} culminating in the first book-length treatment of the subject by Hintikka~\cite{hintikka:1962} in 1962.

\subsection{Common knowledge}

The first work on the topic of common knowledge was by Lewis~\cite{lewis:1969} and later work was by McCarthy, Sato, Hayashi and Igarishi~\cite{mccarthy:1979}.
Common knowledge is described by McCarthy as what ``any fool knows''; for a statement to be common knowledge, it is required that everyone knows that the statement is true, that every agent knows that every agent knows that the statement is true, and so on.
Whereas the definition of common knowledge of Lewis and McCarthy was in terms of modal logics, Aumann~\cite{aumann:1976} gave an alternative definition for common knowledge using Aumann structures and the meet of structures rather than Kripke models and modal formulas.
Common knowledge is of interest in economics and game theory, where common knowledge of rationality, rules and outcomes is assumed in order to permit backwards-induction reasoning about games~\cite{aumann:1995}.
Aumann~\cite{aumann:1976} discusses common knowledge with a focus towards discussing economics and game theory. 
Lehmann~\cite{lehmann:1984} and Halpern and Moses~\cite{halpern:1985} considered common knowledge in depth, and the book by Fagin, Halpern, Moses and Vardi~\cite{fagin:1995} gives a survey of much of their work in this area.

\subsection{Alternative logics of knowledge}

Non-modal logics of knowledge have been considered. 
Aumann~\cite{aumann:1976} proposed an event-based approach using Aumann structures, which represents knowledge as an operator on events rather than reasoning about knowledge using logical formulas.
There is in fact a one-to-one correspondence between epistemic Kripke models and Aumann structures~\cite{fagin:1995}.
A number of authors, among them van Emde Boas, Groenendijk, and Stokhof~\cite{vanemdeboas:1980}, Fagin and Vardi~\cite{fagin:1985}, Mertens and Zamir~\cite{mertens:1985} and Fagin, Halpern and Vardi~\cite{fagin:1991} have considered modeling knowledge and belief using an infinite hierarchy of sets representing the relative strength or plausibility of each piece of knowledge.
This representation lends itself easily to the concept of belief revision, discussed in the next section.
Fagin, Halpern and Vardi~\cite{fagin:1991} discussed the relationship between this representation of knowledge and belief with modal logic.  

%\subsection{Applications of logics of knowledge}

%\begin{enumerate}
    %\item McCarthy 1979 - Knowledge and belief for machines~\cite{mccarthy:1979b}
    %\item Aumann [5~\cite{aumann:1976},6~\cite{aumann:1999},7~\cite{aumann:1995}] -
        %Economics and Game theory

    %\item Orlowska 1989 - Knowledge as operator on events~\cite{orlowska:1989}
    %\item Brandenburger, et al. 1993, etc. - "Direct" representation of
        %knowledge~\cite{brandenburger:1993}
    %\item Fagin, Halpern, Vardi 1991 - Relationship of Brandenburger knowledge
        %to ML~\cite{fagin:1991}
    %\item Levesque 1984a - KD45 as knowledge~\cite{levesque:1984a}
    %\item Fagin and Halpern 1988a, Levesque 1984b - KD45 as
        %belief~\cite{fagin:1987, levesque:1984b}
    %\item Friedman and Halpern 1977, Kraus and Lehmann 1988, Moses and Shoham
        %1933, Voorbraak 1992 - System with knowledge and belief, interaction
    %between knowledge and belief~\cite{friedman:1997, kraus:1988, moses:1993,
    %voorbraak:1992}
    %% TODO AI, economics, game theory
%\end{enumerate}

\section{Logics of specific epistemic updates}

Dynamic epistemic logics consider how knowledge changes as a result of epistemic updates that provide agents with additional information.
For our purposes we generally assume that epistemic updates are purely informative, so they may cause knowledge to change, but not the truth of the propositional atoms that the knowledge is about.
For example, after flipping a coin, if Alice were to tell Bob ``The coin has landed heads up'', this would be a purely informative epistemic update, as the effect is only on Alice and Bob's knowledge.
However the act of Alice flipping the coin would not be purely informative, as it has an effect outside of Alice and Bob's knowledge, specifically on the truth of the statement that ``The coin has landed heads up''.
We also assume that epistemic updates provide additional information monotonically, so they may not cause agents to forget or revise information.
For example, if Alice wasn't wearing her glasses when she looked at the coin she might look again and tell Bob that actually the coin landed tails up, causing Bob to revise the information he was previously offered.
If Alice looks again she might tell Bob that she's now unsure about whether the coin has landed heads up, causing Bob to forget the information he was previously offered, as it was possibly unreliable.

Previous work in dynamic epistemic logic has considered how knowledge changes in response to specific epistemic updates.
These logics typically extend epistemic logic with operators that denote that a specific epistemic update results in a statement becoming true.
For example, we can say that ``After Alice tells Bob that the coin has landed heads up, Bob knows that the coin has landed heads up.''
Logics of this form have been considered for a number of different models for epistemic updates.
Often epistemic updates are modelled as operations on Kripke models, but there are examples of logics where this is not the case.

Notable logics for reasoning about specific epistemic updates include the logic of belief revision of Alchourr{\'o}n, G{\"a}rdenfors and Makinson~\cite{alchourron:1985}, the logic of public announcements of Plaza~\cite{plaza:1989} and Gerbrandy and Groenvald~\cite{gerbrandy:1997}, the logic of epistemic actions of van Ditmarsch~\cite{vanditmarsch:1999, vanditmarsch:2000, vanditmarsch:2002} and the logic of action models of Baltag, Moss and Solecki~\cite{baltag:1999, baltag:2004}.
A survey of these logics and related areas is given in the book by van Ditmarsch, van der Hoek and Kooi~\cite{vanditmarsch:2007}.

\subsection{Public announcement logic}

The public announcement logic was introduced by Plaza~\cite{plaza:1989}, and Gerbrandy and Groenvald~\cite{gerbrandy:1997}.
A public announcement is a simple epistemic update involving a true statement being publicly announced to all agents at once.
The public nature of the announcement means that every agent receives the announcement, every agent knows that every agent receives the announcement, every agents knows that every agents knows that every agent receives the announcement, and so on. 
The effect of publicly announcing a statement is often that the statement becomes common knowledge amongst agents. 
For example, if Alice, Bob and Carol are in a room and Alice publicly announces that ``The coin has landed heads up'' then as a result not only does Bob now know that the coin has landed heads up, Carol knows it as well, and because Bob witnessed Carol receiving the same information, Bob knows that Carol knows, and vice versa.
Public announcement logic extends epistemic logic with an operator that denotes that publicly announcing a true statement results in another statement becoming true.
Public announcements are modelled as an operation on Kripke models by restricting the worlds of the Kripke models to those worlds where the publicly announced statement is true, removing those worlds where the statement is false.

Plaza~\cite{plaza:1989} formulated and axiomatised a multi-agent public announcement logic with common knowledge operators, but without introspection of knowledge, i.e.  agents cannot reason about their own knowledge. 
Gerbrandy and Groenvald~\cite{gerbrandy:1997} formulated and axiomatised a multi-agent public announcement logic without common knowledge operators, but with introspection of knowledge.
Baltag, Moss and Solecki~\cite{baltag:1998,baltag:2004} provided a sound and complete axiomatisation of the public announcement logic with common knowledge operators and introspection of knowledge as a special case of their action model logic with common knowledge.

Public announcements are a very simple form of epistemic update, as the information communicated by a public announcement must be communicated publicly to all agents.
Public announcements cannot model epistemic updates that provide information to only some of the agents in the system, or that provides different information to each agent.
Public announcements are however suited to some interesting problems; for example, Fitch's knowability paradox~\cite{fitch:1963} can be adequately modelled and reasoned about with the public announcement logic, as can the muddy children puzzle~\cite{barwise:1981, vanditmarsch:2007}.

\subsection{Action model logic}

Action models capture a more general notion of epistemic updates than public announcements.
Compared to public announcements, action models are able to represent epistemic updates that provide information privately to some of the agents in the system and provide different information to each agent in the system.
When considering epistemic updates that communicate information privately to some agents, there are a number of ways in which the other agents in the system can interpret that epistemic update. 
For example, suppose that after flipping a coin, Alice looks at the coin so that Bob sees Alice looking at the coin, but Bob can't see the coin himself. Then Bob would know that either Alice knows that the coin has landed heads up or Alice knows that the coin has landed tails up, but Bob himself doesn't know which is actually the case.
If instead Alice were to sneakily look at the coin so that Bob doesn't see her looking, then Alice would know that the coin has landed heads up, but Bob wouldn't know that Alice knows.

Action models are relational structures similar to Kripke models, but nodes in the structure are labelled with epistemic formulas, called preconditions, instead of sets of propositional atoms.
The execution of an action model is represented as an operation that take a Kripke model and an action model, and produces a new Kripke model.
The operation essentially consists of a product between the relational structures of the Kripke model, followed by a restriction of the worlds in the resulting Kripke model, based on the satisfaction of the action models preconditions in worlds of the original Kripke model.
The nodes of the action model and their preconditions can be seen as representing a possible ``action'', an epistemic update that communicates the information in the precondition in some way.
The accessibility relation in the action model is used to represent uncertainty from the point of view of the agents as to which epistemic update actually took place.
Similar to the concept of possible worlds in a Kripke model, in an action model there is a concept of possible actions.
For example, when Alice looks at the coin after flipping it, she only considers one epistemic update to have been possible, where she learns that the coin has landed heads up, whereas Bob considers two epistemic updates to have been possible, one where Alice learns that the coin has landed heads up, and one where Alice learns that the coin has landed tails up.
This uncertainty is represented in an action model by having separate actions in the action model, one representing Alice learning that the coin has landed heads up and one representing Alice learning that the coin has landed tails up, and giving Alice and Bob different accessibility relations over the actions, so that Alice only considers one action possible, but Bob considers both actions possible.

The action model logic was introduced by Baltag, Solecki and Moss~\cite{baltag:1998, baltag:1999}.
Action model logic extends epistemic logic with an operator that denotes that executing a specific action model results in a statement becoming true.
Baltag, Solecki and Moss~\cite{baltag:1998} provided a sound and complete axiomatisation for the logic with and without common knowledge operators.
Later work by Baltag and Moss~\cite{baltag:2004} emphasised the generality of the action model approach, providing many examples of action models representing various kinds of epistemic updates, including public announcements.
Baltag and Moss~\cite{baltag:2004} introduced the notion of an action signature, representing a class of action models that have the same relational structure but which have different formulas as preconditions.
They show that sublanguages of the action model logic can be defined by restricting the possible action models to those corresponding to sets of action signatures, and that the resulting sublanguages have a sound and complete axiomatisation.
This gives for example a sound and complete axiomatisation for the public announcement logic of Gerbrandy and Groenvald~\cite{gerbrandy:1997}, the logic of completely private announcements to groups and the logic of common knowledge of alternatives.

Although the notion of information change that the action model logic captures is intuitively explained in a setting of knowledge, the formulation that Baltag, Moss and Solecki~\cite{baltag:1998} provide is in a more general modal setting that can be applied not only to epistemic logic, but to other modal logics, such as doxastic logics.
Whereas public announcements can only represent true epistemic updates, where the information that is communicated must actually be true in the real world, there is no such restriction for action models.
It is possible in a setting of doxastic logic for an action model to represent epistemic updates containing false information, leading agents to believe that false statements are true.
Baltag and Moss~\cite{baltag:2004} refer to the epistemic updates that action models represent as {\em justifiable changes in belief}, meaning that it is not assumed that action models communicate true information, only that they communicate information that is assumed to be trustworthy.
It is possible for action models to represent intentionally deceptive epistemic updates, such as if Alice knows that the coin has landed heads up, but tells Bob that the coin has landed tails up.
It is also possible for action models to represent unintentionally false epistemic updates, such as if Bob believes that the coin landed tails up, when it in fact did not, but then tells Carol that the coin landed tails up. 
However action models are not capable of {\em revising} beliefs.
That is, after Bob has been lead to believe that the coin has landed tails up, it is not possible to convince him otherwise using an action model.
Action models represent in some sense a monotonic change of knowledge or belief.

\subsection{Belief revision}

In contrast to the true epistemic updates of public announcements, and the justifiable, monotonic epistemic updates of action models, methods for belief revision consider ways in which agents can revise their beliefs in the light of new information.
The system of truth maintenance of Doyle~\cite{doyle:1979} is an early approach to belief revision in the setting of artificial intelligence, which models a ``knowledge base'' of beliefs along with the reasons for those beliefs, which are used to revise those beliefs when contradicting information is discovered. 
Levi~\cite{levi:1983} and Harper~\cite{harper:1976} provided a model of rational belief change which models beliefs and belief revision using Bayesian probability.

More recent developments in belief revision are heavily influenced by the AGM approach to belief revision, named for Alchourr{\'o}n, G{\"a}rdenfors and Makinson~\cite{alchourron:1985}.
The AGM approach models a single agent's beliefs with a belief set, consisting of a set of propositional formulas.
An epistemic update is represented by an operation on the belief set called a revision, which consists of adding a new formula to the belief set, and then removing contradicting formulas from the belief set until the resulting belief set is consistent.
Often there are multiple ways to remove formulas from the belief set that will result in a consistent belief set, and so the AGM approach uses a model of entrenchment, representing how strongly certain beliefs are held, in order to determine which formulas should be removed in favour of others.
Alchourr{\'o}n, G{\"a}rdenfors and Makinson do not provide a logical framework for reasoning about their method of belief revision, and their approach is limited in the sense that it only deals with propositional beliefs, and therefore cannot represent introspective beliefs (beliefs about the agent's own beliefs) or beliefs about other agents' beliefs. 

van Benthem~\cite{vanbenthem:1989, vanbenthem:1994, vanbenthem:1996}, Jaspars~\cite{jaspars:1994} and de Rijke~\cite{derijke:1994} applied dynamic modal logic to doxastic logic to model information change, taking influences from the AGM approach to belief revision.
This provided a logical framework for reasoning about belief revision, however the results still did not allow introspection of beliefs. 
Subsequent work by Lindstr{\"o}m and Rabinowicz~\cite{lindstrom:1999a, lindstrom:1999b} and Segerberg~\cite{segerberg:1999a, segerberg:1999b} developed a full dynamic doxastic logic, allowing reasoning about belief revision with introspective beliefs.
These logics introduce operators that denote that revising an agent's beliefs with a new statement results in another statement becoming true.

%\subsection{Other logics} %\begin{enumerate} %\item Groenendijk and Stokhot [81]~\cite{groenendijk:1991} - Philosophy of information change and
        %linguistics
    %\item Harel and Kozen and Tiuryu [93]~\cite{harel:1983},
        %Pratt~\cite{pratt:1980}, Halpern [17~\cite{benari:1982}, 90~\cite{halpern:1983},
        %28~\cite{berman:1982}], Parikh [161~\cite{parikh:1978}, Goldblatt
            %[79~\cite{goldblatt:1992}] - Dynamic modal
        %logic
    %\item Halpern and Moses [88~\cite{halpern:1985}] - Common knowledge is hard to achieve
    %\item Parikh and Ramanujan [164~\cite{parikh:1985}] - History-based semantics for change of
        %knowledge
    %\item Chandy and Misra [35~\cite{chandy:1986}] - Minimum information flow
    %\item Veltman~\cite{veltman:1996} - Update semantics
%\end{enumerate}
%\begin{enumerate}
    %\item van Ditmarsch [42~\cite{vanditmarsch:1999}, 43~\cite{vanditmarsch:2000},
            %44~\cite{vanditmarsch:2002}] - epistemic actions
    %\item van Benthem and van Eijck and Kooi [26~\cite{vanbenthem:2006}] - Factual change
    %\item Aucher [4~\cite{aucher:2005}], van Ditmarsch
        %[48~\cite{vanditmarsch:2005}], van Benthem and Liu
        %[27~\cite{vanbenthem:2007}]  -
        %Preference-based belief revision
    %\item Leveaque, Lakemeyer, Demolombe [125~\cite{lakemeyer:2000}, 41~\cite{demolombe:2003}] - AI-flavoured semantics
%\end{enumerate}

\section{Logics of arbitrary epistemic updates}

A more recent development in the field of dynamic epistemic logic concerns logics for reasoning about arbitrary epistemic updates.
These logics extend epistemic logic or dynamic epistemic logics for specific epistemic updates with quantifiers that denote either that every epistemic update or some epistemic update results in a statement becoming true.
These quantifiers could be applied to the development of network protocols, where we want to reason about the existence of epistemic protocols that achieve desired knowledge-based goals, or in the verification of secure computer systems, where we want to guarantee that no sequence of operations in the system will lead to sensitive information being leaked to unauthorised agents.

A closely related problem is that of synthesising epistemic updates that achieve desired knowledge-based goals.
For example, in the development of network protocols, if a protocol exists that would achieve a desired knowledge-based goal, then in principle a synthesis procedure could be applied to construct a specific protocol that can be used in practice, or in the verification of secure computer systems, if there is a sequence of operations that results in the system leaking sensitive information, then a synthesis procedure could be applied to construct an example of such a sequence of operations, assisting in debugging and securing the system.

\subsection{Arbitrary public announcement logic}

Early considerations of arbitrary epistemic updates were in relation to the concept of knowability.
A true statement is knowable by an agent if it is possible for the agent to know that it is true.
An example of an unknowable statement was given by Moore (see Hintikka~\cite{hintikka:1962}) which takes the form of ``The coin has landed heads up but Bob doesn't know that the coin has landed heads up''.
If Bob knew that this statement was true, then Bob would know that the coin has landed heads up, but this would contradict the second part of the statement, that says that Bob doesn't know that the coin has landed heads up.
Knowability was considered by Fitch~\cite{fitch:1963} in relation to the verification principle, which says that ``every true statement is knowable''.
Fitch shows that if every true statement is knowable then every true statement must be known; this is known as Fitch's knowability paradox.
It shows that if we accept the verification principle then the notions of truth and knowledge become equivalent, and therefore that the notion of knowledge is redundant in such a setting.
van Benthem~\cite{vanbenthem:2004} considers knowability in the setting of dynamic epistemic logic and dismisses a number of logical treatments of knowledge that attempt to accept the verification principle by weakening the rules for knowledge.
van Benthem~\cite{vanbenthem:2004} also considers the notion of a successful statement, which is a true statement that is known by an agent after it is announced to that agent.
For example, if Bob were to be told that the coin has landed heads up then he would know that the coin has landed heads up, and so ``the coin has landed heads up'' is a successful statement.
All successful statements are knowable, and so the previous example of an unknowable statement is also an example of an unsuccessful statement; after telling Bob that ``the coin has landed heads up and Bob doesn't know that the coin has landed heads up'', Bob does not know that this statement is true because its truth has been invalidated by telling it to Bob.
These treatments of knowable and successful statements introduce an informal syntactic notion of ``what can be known'' that bears some similarity to quantifiers over epistemic updates.

Fitch's knowability paradox partially motivated the work by Balbiani et al.~\cite{balbiani:2007} on the arbitrary public announcement logic.
Arbitrary public announcement logic extends public announcement logic with quantifiers that denote either that every public announcement or some public announcement results in a statement becoming true, allowing one to make statements such as ``there exists a public announcement that results in a statement becoming known'', corresponding to the notion of knowability.
Balbiani et al.~\cite{balbiani:2007} provided a number of semantic results for the arbitrary public announcement logic, along with a sound and complete axiomatisation, however the logic was shown to be undecidable in the setting of multiple agents by French and van Ditmarsch~\cite{french:2008}.
Balbiani et al.~\cite{balbiani:2007} also suggested a generalisation of the arbitrary public announcement logic to quantify over more general classes of epistemic updates, such as action models.

%\begin{enumerate}
    %\item Moore (see Hintikka 1962) - $K(\phi \land \neg K \phi)$~\cite{hintikka:1962}
    %\item Fine~\cite{fine:1970} - Propositional quantifiers
    %\item van Benthem~\cite{vanbenthem:2004} - knowable/successful formulas
    %\item Balbiani et al.~\cite{balbiani:2007} - arbitrary public announcement logic
    %\item van Ditmarsch and French~\cite{vanditmarsch:2008} - undecidability
    %\item Balbiani et al.~\cite{balbiani:2008} - ???
    %\item van Ditmarsch, van der Hoek and Iliev~\cite{vanditmarsch:2011} - ???
%\end{enumerate}

\subsection{Group announcement and coalition announcement logic}

Two logics related to the arbitrary public announcement logic are the group announcement and coalition announcement logics of {\AA}gotnes and van Ditmarsch~\cite{agotnes:2008,agotnes:2010}. 
Compared to the quantifiers of arbitrary public announcement logic, group announcement logic restricts the public announcements that are quantified over to group announcements.
A group announcement consists of a public announcement that each agent in a group knows a particular statement is true.
Each agent may only announce statements that they actually know to be true.
Group announcement logic extends public announcement logic with quantifiers that denote, for a given group of agents, either that every group announcement or some group announcement that can be made by the group results in a statement becoming true.
Coalition announcements is similar, but differs from group announcements in that agents outside of the coalition are also able to make public announcements that may sabotage whatever the coalition of agents is attempting to achieve through its announcements.
{\AA}gotnes et al.~\cite{agotnes:2010} provide a sound and complete axiomatisation of the group announcement logic, along with expressivity results and a complexity result for model checking, and {\AA}gotnes, van Ditmarsch and French~\cite{agotnes:2014} showed that group announcement logic is undecidable.
It is yet unknown whether the group announcement logic and coalition announcement logic are expressively equivalent.

%\begin{enumerate}
    %\item {\AA}gotnes et al.~\cite{agotnes:2010} - group announcement logic
    %\item Pauly~\cite{pauly:2001} - GAL embeds coalition logic
    %\item de Lima~\cite{delima:2011} - Alternating time temporal announcement logic
    %\item {\AA}gotnes and van Ditmarsch~\cite{aagotnes:2008b} - Coalitions and announcements ???
%\end{enumerate}

\subsection{Refinement modal logic}

Whereas group announcement and coalition announcement logics of {\AA}gotnes and van Ditmarsch~\cite{agotnes:2008} restricted the epistemic updates that are quantified over, compared to arbitrary announcement logic, the refinement modal logic of van Ditmarsch and French~\cite{vanditmarsch:2009} introduces quantifiers quantify over a much more general class of epistemic updates.
Refinement modal logic is related to the bisimulation quantified modal logic of French~\cite{french:2006}, which introduces an operator for quantifying over the pointed Kripke models that are bisimilar to the pointed Kripke model currently being considered, except for the value of a propositional atom that is allowed to vary.
Bisimulations are an important concept in the semantics of modal logics, that correspond to a notion of equivalence of Kripke models: if two pointed Kripke models are bisimilar then they are indistinguishable to any modal formula.
For two Kripke models to be considered bisimilar there must exist a bisimulation relation that satisfies the three conditions known as {\bf atoms}, {\bf forth} and {\bf back}.
Refinements are related to bisimulations: for a Kripke model to be a refinement of another Kripke model, there must exist a refinement relation that satisfies {\bf atoms} and {\bf forth}.
Refinements can be seen as one direction of a bisimulation; whereas bisimulation corresponds to an equivalence relation, refinement corresponds to a partial ordering.
The refinement modal logic of van Ditmarsch and French~\cite{vanditmarsch:2009} quantifies over the pointed Kripke models that are refinements of the pointed Kripke model currently being considered.
Whereas the quantifier in the bisimulation quantified modal logic of French~\cite{french:2006} binds a propositional atom as a variable, the quantifier in refinement modal logic binds no variables.
van Ditmarsch and French~\cite{vanditmarsch:2009} provide several semantic results to justify that refinements correspond to a very general notion of epistemic updates.
In particular, the result of executing any action model on a Kripke model is a refinement of the original Kripke model, and any refinement of a finite Kripke model corresponds to the result of executing some action model~\cite{vanditmarsch:2009}.
van Ditmarsch and French~\cite{vanditmarsch:2009} also compare their refinement modal logic to the arbitrary action model logic suggested by Balbiani et al.~\cite{balbiani:2007}, conjecturing that adding the operator from the action model logic to the refinement modal logic yields a logic equivalent to the arbitrary action model logic.

Refinement modal logic is considered in further detail by van Ditmarsch, French and Pinchinat~\cite{vanditmarsch:2010}, who provide a sound and complete axiomatisation for the single agent refinement modal logic over the class of all Kripke models.
The axiomatisation given for refinement modal logic have the form of reduction axioms, allowing formulas containing refinement quantifiers to be translated into modal formulas without refinement quantifiers.
A consequence of this is that single agent refinement modal logic over the class of all Kripke models is expressively equivalent to the single agent modal logic over the class of all Kripke models, and that the logic is decidable.

In addition to axiomatisations, decidability and expressivity results, van Ditmarsch, French and Pinchinat~\cite{vanditmarsch:2010} provided results for refinement modal $\mu$-calculus, which adds a refinement quantifier to the modal $\mu$-calculus, Bozzelli, van Ditmarsch and Pinchinat~\cite{bozzelli:2014a} showed complexity and succinctness results for the single-agent refinement modal logic over the \classK{} of all Kripke models, and Achilleos and Lampis~\cite{achilleos:2013} provided tighter complexity results for the decision problem and showed that the model-checking problem is PSPACE-complete.
